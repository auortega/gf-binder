{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f434fef85f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the SpaCy model for English\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Load the SpaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to process each sentence\n",
    "def process_sentence(sentence, word_repository):\n",
    "    doc = nlp(sentence)\n",
    "    tokens_data = []\n",
    "    dependencies = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Add word to the repository with its POS tag\n",
    "        word_repository[token.pos_][token.text] += 1\n",
    "\n",
    "        # Collect token data\n",
    "        tokens_data.append({\n",
    "            \"text\": token.text,\n",
    "            \"pos\": token.pos_,\n",
    "            \"dep\": token.dep_,\n",
    "            \"head\": token.head.text\n",
    "        })\n",
    "\n",
    "        # Collect dependency data\n",
    "        dependencies.append({\n",
    "            \"dependent\": token.text,\n",
    "            \"head\": token.head.text,\n",
    "            \"relation\": token.dep_\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"sentence\": sentence,\n",
    "        \"tokens\": tokens_data,\n",
    "        \"dependencies\": dependencies\n",
    "    }\n",
    "\n",
    "# Read sentences from a .txt file\n",
    "file_path = 'input.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = text.split('\\n')\n",
    "\n",
    "# Initialize the word repository and results list\n",
    "word_repository = defaultdict(Counter)\n",
    "results = []\n",
    "\n",
    "# Process each sentence\n",
    "for sentence in sentences:\n",
    "    if sentence.strip():  # Ensure the sentence is not empty\n",
    "        sentence_data = process_sentence(sentence, word_repository)\n",
    "        results.append(sentence_data)\n",
    "\n",
    "# Sort words in each POS tag by their counts\n",
    "sorted_word_repository = {pos: sorted(words.items(), key=lambda item: item[1], reverse=True)\n",
    "                          for pos, words in word_repository.items()}\n",
    "\n",
    "# Output the results to a JSON file\n",
    "output_path = 'output.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=2)\n",
    "\n",
    "# Output the sorted word repository to a JSON file\n",
    "word_repository_path = 'word_repository.json'\n",
    "with open(word_repository_path, 'w') as json_file:\n",
    "    json.dump(sorted_word_repository, json_file, indent=2)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_path} and {word_repository_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 70.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (20.4)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 100.6 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.11.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 97.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "\u001b[K     |████████████████████████████████| 381 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (47.1.1.post20200529)\n",
      "Collecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (921 kB)\n",
      "\u001b[K     |████████████████████████████████| 921 kB 39.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting numpy>=1.15.0; python_version < \"3.9\"\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 60.5 MB/s eta 0:00:01�████▋                       | 4.2 MB 60.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 92.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.46.1)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "\u001b[K     |████████████████████████████████| 491 kB 74.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 130.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.1.0)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 94.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting confection<0.2.0,>=0.0.4\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 115.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting pydantic-core==2.14.6\n",
      "  Downloading pydantic_core-2.14.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 79.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version == \"3.7\" in /opt/conda/lib/python3.7/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (1.6.1)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2 MB 66.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rich>=10.11.0\n",
      "  Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 126.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click>=8.0.0\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 114.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 96.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 54.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 62.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement ipykernel>=6.14, but you'll have ipykernel 5.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 6.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement jupyter-core!=5.0.*,>=4.12, but you'll have jupyter-core 4.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement prompt-toolkit>=3.0.30, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.6.3 has requirement traitlets>=5.4, but you'll have traitlets 4.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cymem, typing-extensions, catalogue, cloudpathlib, srsly, pydantic-core, annotated-types, pydantic, confection, wasabi, wrapt, smart-open, mdurl, markdown-it-py, pygments, rich, click, shellingham, typer, weasel, langcodes, spacy-legacy, numpy, blis, murmurhash, preshed, thinc, spacy-loggers, spacy\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.6.1\n",
      "    Uninstalling Pygments-2.6.1:\n",
      "      Successfully uninstalled Pygments-2.6.1\n",
      "Successfully installed annotated-types-0.5.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 langcodes-3.3.0 markdown-it-py-2.2.0 mdurl-0.1.2 murmurhash-1.0.10 numpy-1.21.6 preshed-3.0.9 pydantic-2.5.3 pydantic-core-2.14.6 pygments-2.17.2 rich-13.7.1 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.4 typer-0.12.3 typing-extensions-4.7.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Test it on a sample text\n",
    "doc = nlp(\"This is a test sentence.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
